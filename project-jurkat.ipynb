{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cell_dataset_exp_Jurkat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvCGua5L9CoQ8+IhDvLq6p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mainakdeb/project-jurkat/blob/main/project-jurkat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zleh-QpS-DjJ"
      },
      "source": [
        "# Work in progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP9O31vLSGW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6809b5fd-2770-4830-d575-86300cf55d04"
      },
      "source": [
        "!pip install iterative-stratification"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.6/dist-packages (0.1.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from iterative-stratification) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->iterative-stratification) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpReG0xtq-Iy"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9wHZPySdaho"
      },
      "source": [
        "import pandas as pd\r\n",
        "import torch\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from albumentations import *\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from tqdm.notebook import tnrange, tqdm\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\r\n",
        "from torchvision import models \r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import time\r\n",
        "import pytorch_lightning as pl\r\n",
        "import seaborn as sns\r\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2_f0TKUUXuQ",
        "outputId": "fdd77039-9990-40cd-8c87-7130942f63c2"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "device"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqc__28L6km7"
      },
      "source": [
        "!wget https://data.broadinstitute.org/bbbc/BBBC048/BBBC048v1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPi1jk2L64Li"
      },
      "source": [
        "!wget https://data.broadinstitute.org/bbbc/BBBC048/Ground_truth.lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPeDfchS2_7a"
      },
      "source": [
        "!unzip \"/content/BBBC048v1.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn6yCOFI5H6_"
      },
      "source": [
        "!unzip \"/content/CellCycle.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOD61hs_7NGd"
      },
      "source": [
        "my_file = open(\"/content/Ground_truth.lst\", \"r\")\r\n",
        "content = my_file.read()\r\n",
        "print(type(content))\r\n",
        "print(content[0:200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6SKzLdA7jXH"
      },
      "source": [
        "dataframe1 = pd.read_csv(\"/content/Ground_truth.lst\",\r\n",
        "                          header=None) "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWmvfSwe8d7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "3d2d749d-1280-45e1-b8a2-7d93d2969d7d"
      },
      "source": [
        "df=dataframe1[0].str.split(expand=True)\r\n",
        "df=df.sample(frac=1)\r\n",
        "df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33571</th>\n",
              "      <td>32226</td>\n",
              "      <td>4</td>\n",
              "      <td>./G1/44782_Ch4.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53373</th>\n",
              "      <td>54050</td>\n",
              "      <td>5</td>\n",
              "      <td>./G2/28244_Ch3.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61122</th>\n",
              "      <td>58850</td>\n",
              "      <td>5</td>\n",
              "      <td>./G2/4172_Ch3.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96372</th>\n",
              "      <td>87251</td>\n",
              "      <td>6</td>\n",
              "      <td>./S/940_Ch3.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19313</th>\n",
              "      <td>6640</td>\n",
              "      <td>4</td>\n",
              "      <td>./G1/30102_Ch6.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9263</th>\n",
              "      <td>16154</td>\n",
              "      <td>4</td>\n",
              "      <td>./G1/1960_Ch6.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47342</th>\n",
              "      <td>58885</td>\n",
              "      <td>5</td>\n",
              "      <td>./G2/1777_Ch6.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47667</th>\n",
              "      <td>66552</td>\n",
              "      <td>5</td>\n",
              "      <td>./G2/18420_Ch3.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51070</th>\n",
              "      <td>51746</td>\n",
              "      <td>5</td>\n",
              "      <td>./G2/24189_Ch4.ome.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28805</th>\n",
              "      <td>39404</td>\n",
              "      <td>4</td>\n",
              "      <td>./G1/39742_Ch6.ome.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96798 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0  1                       2\n",
              "33571  32226  4  ./G1/44782_Ch4.ome.jpg\n",
              "53373  54050  5  ./G2/28244_Ch3.ome.jpg\n",
              "61122  58850  5   ./G2/4172_Ch3.ome.jpg\n",
              "96372  87251  6     ./S/940_Ch3.ome.jpg\n",
              "19313   6640  4  ./G1/30102_Ch6.ome.jpg\n",
              "...      ... ..                     ...\n",
              "9263   16154  4   ./G1/1960_Ch6.ome.jpg\n",
              "47342  58885  5   ./G2/1777_Ch6.ome.jpg\n",
              "47667  66552  5  ./G2/18420_Ch3.ome.jpg\n",
              "51070  51746  5  ./G2/24189_Ch4.ome.jpg\n",
              "28805  39404  4  ./G1/39742_Ch6.ome.jpg\n",
              "\n",
              "[96798 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ea9aqBK55w"
      },
      "source": [
        "#generate csv\r\n",
        "\r\n",
        "import os, csv\r\n",
        "\r\n",
        "cell_df = pd.DataFrame(list())\r\n",
        "cell_df.to_csv('cell_cycle.csv')\r\n",
        "\r\n",
        "f=open(\"cell_cycle.csv\",'r+')\r\n",
        "w=csv.writer(f)\r\n",
        "\r\n",
        "folders = [\"Anaphase\", \"G1\", \"G2\",\"Metaphase\", \"Prophase\", \"S\", \"Telophase\"]\r\n",
        "folders2 = [\"G1\",\"G2\",\"S\"]\r\n",
        "\r\n",
        "for f in folders2:\r\n",
        "  for path, dirs, files in os.walk(\"/content/CellCycle/\"+f+\"/\"):\r\n",
        "      for filename in files:\r\n",
        "          w.writerow([path+filename, f])\r\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0mTdAMONQZN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "072225e0-89f1-44fd-9929-14f3e8ec0c0f"
      },
      "source": [
        "c = pd.read_csv('./cell_cycle.csv', header=None)\r\n",
        "c.columns = [\"path\",\"class_name\"]\r\n",
        "print(c.class_name.unique())\r\n",
        "c"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['G1' 'G2' 'S']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/CellCycle/G1/44410_Ch6.ome.jpg</td>\n",
              "      <td>G1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/CellCycle/G1/49778_merged.jpg</td>\n",
              "      <td>G1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/CellCycle/G1/3853_Ch6.ome.jpg</td>\n",
              "      <td>G1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/CellCycle/G1/19185_merged.jpg</td>\n",
              "      <td>G1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/CellCycle/G1/27736_Ch3.ome.jpg</td>\n",
              "      <td>G1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126195</th>\n",
              "      <td>/content/CellCycle/S/13505_Ch3.ome.jpg</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126196</th>\n",
              "      <td>/content/CellCycle/S/24533_merged.jpg</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126197</th>\n",
              "      <td>/content/CellCycle/S/49426_merged.jpg</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126198</th>\n",
              "      <td>/content/CellCycle/S/25806_Ch4.ome.jpg</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126199</th>\n",
              "      <td>/content/CellCycle/S/22234_Ch3.ome.jpg</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>126200 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           path class_name\n",
              "0       /content/CellCycle/G1/44410_Ch6.ome.jpg         G1\n",
              "1        /content/CellCycle/G1/49778_merged.jpg         G1\n",
              "2        /content/CellCycle/G1/3853_Ch6.ome.jpg         G1\n",
              "3        /content/CellCycle/G1/19185_merged.jpg         G1\n",
              "4       /content/CellCycle/G1/27736_Ch3.ome.jpg         G1\n",
              "...                                         ...        ...\n",
              "126195   /content/CellCycle/S/13505_Ch3.ome.jpg          S\n",
              "126196    /content/CellCycle/S/24533_merged.jpg          S\n",
              "126197    /content/CellCycle/S/49426_merged.jpg          S\n",
              "126198   /content/CellCycle/S/25806_Ch4.ome.jpg          S\n",
              "126199   /content/CellCycle/S/22234_Ch3.ome.jpg          S\n",
              "\n",
              "[126200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AYegRBWPEXf"
      },
      "source": [
        "#delete non merged rows\r\n",
        "c_merged=c[c.path.str[-10:] == \"merged.jpg\"]\r\n",
        "c_merged.to_csv(\"cell_merged.csv\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQW8cAUgfjIh"
      },
      "source": [
        "def image_to_nparray(path):\r\n",
        "    i = cv2.imread(path)\r\n",
        "    i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\r\n",
        "    return(np.array(i))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNcQSSj9YxQ"
      },
      "source": [
        "class C_Dataset(Dataset):\r\n",
        "    \"\"\"custom\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, csv, root_dir='',augmentation=None, transform=None):\r\n",
        "        \r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            csv_file (string): Path to the csv file with annotations.\r\n",
        "            root_dir (string): Directory with all the images.\r\n",
        "            transform (callable, optional): Optional transform to be applied\r\n",
        "                on a sample.\r\n",
        "        \"\"\"\r\n",
        "        \r\n",
        "        self.transform = transform\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.d = csv\r\n",
        "        self.augmentation = augmentation\r\n",
        "        self.class_dict = {'G1':0,\r\n",
        "                           'S': 1,\r\n",
        "                           'G2':2}\r\n",
        "        \r\n",
        "    def __getitem__(self, idx): \r\n",
        "\r\n",
        "        smol_img_path = str(self.d.iloc[idx][1]) #image path column\r\n",
        "        #print(smol_img_path)\r\n",
        "        class_name = str(self.d.iloc[idx][2])  #class name column\r\n",
        "        #print(\"class............\",class_name)\r\n",
        "        #print(class_name)\r\n",
        "        full_img_path = self.root_dir + smol_img_path #+ '.png'\r\n",
        "\r\n",
        "        #print(full_img_path)\r\n",
        "\r\n",
        "        img_arr = image_to_nparray(full_img_path)\r\n",
        "\r\n",
        "        if self.augmentation is not None:\r\n",
        "            img  = self.augmentation(image = img_arr)\r\n",
        "            img2 = img[\"image\"]\r\n",
        "            #print(img2)\r\n",
        "\r\n",
        "        if self.transform is not None:\r\n",
        "            img_ret = self.transform(img2)\r\n",
        "            #print(img_ret)\r\n",
        "        \r\n",
        "        #return self.class_dict[str(class_name)], img_ret\r\n",
        "        return {\"x\": img_ret,\r\n",
        "                \"y\": torch.tensor(self.class_dict[str(class_name)])\r\n",
        "        }\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "      \r\n",
        "        return (len(self.d))\r\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCFv5EMKQo07"
      },
      "source": [
        "data = C_Dataset(pd.read_csv('/content/cell_merged.csv'), \r\n",
        "                 '',\r\n",
        "                 augmentation = Compose([ \r\n",
        "                                        #RandomBrightnessContrast( p=0.9),\r\n",
        "                                        Rotate(limit=30, interpolation=1, border_mode=4, always_apply=True, p=0.9)\r\n",
        "                                        ]),\r\n",
        "                transform = transforms.Compose([    \r\n",
        "                                                transforms.ToPILImage(),\r\n",
        "                                                transforms.Resize((224,224)),\r\n",
        "                                                transforms.CenterCrop((128,128)),\r\n",
        "                                                transforms.ToTensor()\r\n",
        "                                                ])\r\n",
        "                )"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-CV87fydw4v"
      },
      "source": [
        "train_dl = torch.utils.data.DataLoader(\r\n",
        "    data\r\n",
        "    ,batch_size=64\r\n",
        "    ,shuffle=True\r\n",
        "    # ,pin_memory=True\r\n",
        "    # ,num_workers=4\r\n",
        ")\r\n",
        "\r\n",
        "for data in tqdm(train_dl):\r\n",
        "    print(\"size: \",data['x'][0].size())\r\n",
        "    plt.imshow(data['x'][0].permute(1,2,0))\r\n",
        "    plt.show()\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdDfx-ALM2JE"
      },
      "source": [
        "fig, ax = plt.subplots(3,3, figsize = (15,15))\r\n",
        "class_dict = {'G1':0,\r\n",
        "              'S': 1,\r\n",
        "              'G2':2}\r\n",
        "\r\n",
        "for i in range (9):\r\n",
        "  batch = next(iter(train_dl))\r\n",
        "  image, label=batch['x'],batch['y']\r\n",
        "  #print(label)\r\n",
        "  ax.flat[i].imshow(image[0].permute(1,2,0))\r\n",
        "  \r\n",
        "  text = \"Class: \"+list(class_dict.keys())[int(label[0])]\r\n",
        "  ax.flat[i].set_xlabel(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16L6iLjcb593"
      },
      "source": [
        "#create a subset\r\n",
        "df = pd.read_csv('/content/cell_merged.csv')\r\n",
        "df = df.sample(frac=1)\r\n",
        "# iloc[row slicing, column slicing]\r\n",
        "subset_df = df.iloc[0:5000, 1:]\r\n",
        "subset_df.to_csv(\"cell_merged_subset.csv\")"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNJ3LqScQ8gL"
      },
      "source": [
        "#create folds\r\n",
        "df = pd.read_csv('/content/cell_merged_subset.csv')\r\n",
        "\r\n",
        "df.loc[:,\"kfold\"] = -1\r\n",
        "\r\n",
        "#df = df.sample(frac=1).reset_index(drop=True)\r\n",
        "\r\n",
        "targets = df.drop(\"class_name\", axis=1).values\r\n",
        "\r\n",
        "NFOLDS = 10\r\n",
        "mskf = MultilabelStratifiedKFold(n_splits = NFOLDS)\r\n",
        "for fold, (trn, val) in enumerate(mskf.split(X=df, y = targets)):\r\n",
        "    df.loc[val, \"kfold\"] = fold\r\n",
        "    \r\n",
        "df.to_csv(\"./train_targets_folds.csv\", index=False)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "jtNBwX0jSQ31",
        "outputId": "dec513dc-ef53-4099-b8ba-43b9c69a8bb6"
      },
      "source": [
        "train_csv = pd.read_csv('./train_targets_folds.csv')\r\n",
        "train_csv.head()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19940</td>\n",
              "      <td>/content/CellCycle/G2/38978_merged.jpg</td>\n",
              "      <td>G2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26669</td>\n",
              "      <td>/content/CellCycle/S/47182_merged.jpg</td>\n",
              "      <td>S</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14582</td>\n",
              "      <td>/content/CellCycle/G2/21078_merged.jpg</td>\n",
              "      <td>G2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30537</td>\n",
              "      <td>/content/CellCycle/S/36157_merged.jpg</td>\n",
              "      <td>S</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5470</td>\n",
              "      <td>/content/CellCycle/G1/32666_merged.jpg</td>\n",
              "      <td>G1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                    path class_name  kfold\n",
              "0       19940  /content/CellCycle/G2/38978_merged.jpg         G2      4\n",
              "1       26669   /content/CellCycle/S/47182_merged.jpg          S      6\n",
              "2       14582  /content/CellCycle/G2/21078_merged.jpg         G2      7\n",
              "3       30537   /content/CellCycle/S/36157_merged.jpg          S      5\n",
              "4        5470  /content/CellCycle/G1/32666_merged.jpg         G1      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUj5NCDviUWB"
      },
      "source": [
        "#####################################\r\n",
        "class_names = ['G1', 'S', 'G2']\r\n",
        "\r\n",
        "'''Load a predefined model & \r\n",
        "   reset the fully connected layer to add dropout + \r\n",
        "   change the number of classes'''\r\n",
        "torch.cuda.empty_cache()\r\n",
        "model = models.resnet101(pretrained=False)\r\n",
        "num_ftrs = model.fc.in_features\r\n",
        "model.fc = nn.Sequential(nn.Dropout(0.5),nn.Linear(num_ftrs, len(class_names)))\r\n",
        "\r\n",
        "'''Load model to device'''\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "model = model.to(device)\r\n",
        "\r\n",
        "'''Set evaluation criterion and optimization algorithm'''\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.00001)\r\n",
        "\r\n",
        "train_losses = []\r\n",
        "valid_losses = []\r\n",
        "train_accuracy = []\r\n",
        "valid_accuracy = []\r\n",
        "\r\n",
        "def train_model(model, criterion, optimizer, num_epochs):\r\n",
        "  start_time = time.time()\r\n",
        "  for epoch in range(1, num_epochs + 1):\r\n",
        "    print('Epoch {}/{}'.format(epoch , num_epochs))\r\n",
        "    print('-*-' * 5)\r\n",
        "    \r\n",
        "    # TRAINING LOOP\r\n",
        "    train_loss = 0.0\r\n",
        "    valid_loss = 0.0\r\n",
        "    total_tr = 0.0\r\n",
        "    correct_tr = 0.0\r\n",
        "    model.train()\r\n",
        "    for batch in train_dl:\r\n",
        "\r\n",
        "      data, target=batch['x'].to(device), batch['y'].to(device)\r\n",
        "      optimizer.zero_grad()\r\n",
        "      # Forward Pass\r\n",
        "      output = model(data)\r\n",
        "      loss = criterion(output, target)\r\n",
        "      # Backward Pass  \r\n",
        "      loss.backward()\r\n",
        "      # Update loss and accuracy\r\n",
        "      optimizer.step()\r\n",
        "      train_loss += loss.item() * data.size(0)\r\n",
        "      _,predicted = torch.max(output.data, 1)\r\n",
        "      total_tr += target.size(0)\r\n",
        "      correct_tr += (predicted == target).sum().item()\r\n",
        "        \r\n",
        "    # VALIDATION LOOP\r\n",
        "    model.eval()\r\n",
        "    total_vl = 0.0\r\n",
        "    correct_vl = 0.0\r\n",
        "    for batch in train_dl: \r\n",
        "      data, target=batch['x'].to(device), batch['y'].to(device)\r\n",
        "      # Forward Pass      \r\n",
        "      output = model(data)   \r\n",
        "      loss = criterion(output, target)       \r\n",
        "      # Update loss and accuracy\r\n",
        "      valid_loss += loss.item() * data.size(0)\r\n",
        "      _,predicted = torch.max(output.data, 1)\r\n",
        "      total_vl += target.size(0)\r\n",
        "      correct_vl += (predicted == target).sum().item()\r\n",
        "  \r\n",
        "    # Determine and update loss averages\r\n",
        "    train_loss = train_loss/len(train_dl.sampler)\r\n",
        "    valid_loss = valid_loss/len(train_dl.sampler)\r\n",
        "    train_losses.append(train_loss)\r\n",
        "    valid_losses.append(valid_loss)\r\n",
        "    \r\n",
        "    # Determine and update mean accuracy\r\n",
        "    tr_accuracy = (100 * correct_tr/total_tr)\r\n",
        "    vl_accuracy = (100 * correct_vl/total_vl)\r\n",
        "    train_accuracy.append(tr_accuracy)\r\n",
        "    valid_accuracy.append(vl_accuracy)\r\n",
        "    \r\n",
        "    # Display stats for each epoch\r\n",
        "    print('Training Loss: {:.4f} Validation Loss: {:.4f}'.format(train_loss, valid_loss))\r\n",
        "    print('Training Accuracy: {:.4f} Validation Accuracy: {:.4f}'.format( tr_accuracy, vl_accuracy))\r\n",
        "\r\n",
        "  time_elapsed = time.time() - start_time\r\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n",
        "  return model\r\n",
        "model = train_model(model, criterion, optimizer, num_epochs=30)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuhAMTrvMZNR"
      },
      "source": [
        "class Engine:\r\n",
        "  #something wrong here\r\n",
        "      def __init__(self, model, optimizer, device, scheduler, criterion):\r\n",
        "        self.model = model\r\n",
        "        self.device = device\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.scheduler = scheduler\r\n",
        "        self.criterion=criterion\r\n",
        "\r\n",
        "      def train(self, data_loader):\r\n",
        "        train_loss = 0.0\r\n",
        "        valid_loss = 0.0\r\n",
        "        total_tr = 0.0\r\n",
        "        correct_tr = 0.0\r\n",
        "        self.model.train()\r\n",
        "        for batch in tqdm(data_loader):##\r\n",
        "          data, target=batch['x'].to(self.device), batch['y'].to(self.device)\r\n",
        "          self.optimizer.zero_grad()\r\n",
        "          # Forward Pass\r\n",
        "          output = self.model(data)\r\n",
        "          loss = self.criterion(output, target)\r\n",
        "          # Backward Pass  \r\n",
        "          loss.backward()\r\n",
        "          # Update loss and accuracy\r\n",
        "          self.optimizer.step()\r\n",
        "          train_loss += loss.item() * data.size(0)\r\n",
        "          _,predicted = torch.max(output.data, 1)\r\n",
        "          total_tr += target.size(0)\r\n",
        "          correct_tr += (predicted == target).sum().item()\r\n",
        "        #self.scheduler.step(1.)\r\n",
        "        return(train_loss/len(data_loader.sampler), 100*correct_tr/total_tr)\r\n",
        "\r\n",
        "      def evaluate(self, data_loader):\r\n",
        "        self.model.eval()\r\n",
        "        final_loss=0\r\n",
        "        for data in data_loader:\r\n",
        "            #self.optimizer.zero_grad()\r\n",
        "            inputs = data[\"x\"].to(self.device)\r\n",
        "            targets = data[\"y\"].to(self.device)\r\n",
        "            outputs = self.model(inputs)\r\n",
        "            loss = self.loss_fn(targets, outputs)\r\n",
        "            #loss.backward()\r\n",
        "            #self.optimizer.step()\r\n",
        "            final_loss += loss.item()\r\n",
        "        return(final_loss)\r\n"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJkR32UeNzDE"
      },
      "source": [
        "def run_training(fold, batch_size, lr, save_model=True, num_epochs = 1):\r\n",
        "\r\n",
        "    val_fold=train_csv[train_csv['kfold'] == fold]\r\n",
        "    train_fold=train_csv[train_csv['kfold'] != fold]\r\n",
        "    \r\n",
        "    \r\n",
        "    train_dataset = C_Dataset(train_fold, \r\n",
        "                 '',\r\n",
        "                 augmentation = Compose([ \r\n",
        "                                        #RandomBrightnessContrast( p=0.9),\r\n",
        "                                        Rotate(limit=30, interpolation=1, border_mode=4, always_apply=True, p=0.9)\r\n",
        "                                        ]),\r\n",
        "                transform = transforms.Compose([    \r\n",
        "                                                transforms.ToPILImage(),\r\n",
        "                                                transforms.Resize((224,224)),\r\n",
        "                                                transforms.CenterCrop((128,128)),\r\n",
        "                                                transforms.ToTensor()\r\n",
        "                                                ])\r\n",
        "                )\r\n",
        "    valid_dataset = C_Dataset(val_fold, \r\n",
        "                 '',\r\n",
        "                 augmentation = Compose([ \r\n",
        "                                        #RandomBrightnessContrast( p=0.9),\r\n",
        "                                        Rotate(limit=30, interpolation=1, border_mode=4, always_apply=True, p=0.9)\r\n",
        "                                        ]),\r\n",
        "                transform = transforms.Compose([    \r\n",
        "                                                transforms.ToPILImage(),\r\n",
        "                                                transforms.Resize((224,224)),\r\n",
        "                                                transforms.CenterCrop((128,128)),\r\n",
        "                                                transforms.ToTensor()\r\n",
        "                                                ])\r\n",
        "                )\r\n",
        "    \r\n",
        "    train_loader = torch.utils.data.DataLoader(\r\n",
        "                    train_dataset\r\n",
        "                    ,batch_size=batch_size\r\n",
        "                    ,shuffle=True\r\n",
        "                )\r\n",
        "\r\n",
        "    val_loader = torch.utils.data.DataLoader(\r\n",
        "                    valid_dataset\r\n",
        "                    ,batch_size=32\r\n",
        "                    ,shuffle=True\r\n",
        "                )\r\n",
        "\r\n",
        "    torch.cuda.empty_cache()\r\n",
        "    model_ft = models.resnet101(pretrained=False)\r\n",
        "    num_ftrs = model_ft.fc.in_features\r\n",
        "    model_ft.fc = nn.Sequential(nn.Dropout(0.5),nn.Linear(num_ftrs, 3))\r\n",
        "    model = model_ft.to(device)\r\n",
        "    \r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.00001)\r\n",
        "    \r\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \r\n",
        "                                                 mode='min', \r\n",
        "                                                 factor=0.1,\r\n",
        "                                                 patience=7, \r\n",
        "                                                 eps=1e-4, \r\n",
        "                                                 verbose=True)\r\n",
        "    eng = Engine(model,\r\n",
        "                 optimizer, \r\n",
        "                 device='cuda', \r\n",
        "                 scheduler = scheduler,\r\n",
        "                 criterion=criterion)\r\n",
        "    \r\n",
        "    best_loss = 999\r\n",
        "    early_stop_iter = 10\r\n",
        "    early_stop_count=0\r\n",
        "\r\n",
        "    for epoch in tnrange(num_epochs):\r\n",
        "        train_loss, train_accuracy = eng.train(train_loader)\r\n",
        "        #valid_loss = eng.evaluate(val_loader)\r\n",
        "        print(\"train_loss: {:.4f} train_acc: {:.4f}\".format(train_loss, train_accuracy))#, \"val_loss:\", valid_loss)\r\n",
        "        #print(tot)\r\n",
        "        # if valid_loss<best_loss:\r\n",
        "        #     best_loss = valid_loss\r\n",
        "        #     if save_model:\r\n",
        "        #         torch.save(model.state_dict(), \"model_\"+str(fold)+\".pth\")\r\n",
        "        # else:\r\n",
        "        #     early_stop_count +=1\r\n",
        "            \r\n",
        "        # if early_stop_count>early_stop_iter:\r\n",
        "        #     break\r\n",
        "                    \r\n",
        "    return(best_loss)\r\n",
        "    #to do: accuracy"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxKEdQB_N9kL"
      },
      "source": [
        "best_losses = []\r\n",
        "\r\n",
        "for fold in range(NFOLDS):\r\n",
        "    best_losses.append(\r\n",
        "        run_training(\r\n",
        "            fold=fold,\r\n",
        "            batch_size = 32,#best_params[\"batch_size\"],\r\n",
        "            lr = 0.0001,#best_params[\"lr\"],\r\n",
        "            num_epochs = 20\r\n",
        "        )\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG4hHN5jeNXs"
      },
      "source": [
        "data_sub = C_Dataset(pd.read_csv('/content/cell_merged_subset.csv'), \r\n",
        "                 '',\r\n",
        "                 augmentation = Compose([ \r\n",
        "                                        #RandomBrightnessContrast( p=0.9),\r\n",
        "                                        Rotate(limit=30, interpolation=1, border_mode=4, always_apply=True, p=0.9)\r\n",
        "                                        ]),\r\n",
        "                transform = transforms.Compose([    \r\n",
        "                                                transforms.ToPILImage(),\r\n",
        "                                                transforms.Resize((224,224)),\r\n",
        "                                                transforms.CenterCrop((128,128)),\r\n",
        "                                                transforms.ToTensor()\r\n",
        "                                                ])\r\n",
        "                )\r\n",
        "\r\n",
        "train_dl_sub = torch.utils.data.DataLoader(\r\n",
        "    data_sub\r\n",
        "    ,batch_size=64\r\n",
        "    ,shuffle=True\r\n",
        "    # ,pin_memory=True\r\n",
        "    # ,num_workers=4\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKVmXPJ3bz_k",
        "outputId": "25996b14-0f3c-40a0-ab94-dbd8ba2d3e59"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\r\n",
        "num_ftrs = model_ft.fc.in_features\r\n",
        "model_ft.fc = nn.Sequential(nn.Dropout(0.5),nn.Linear(num_ftrs, 3))\r\n",
        "model = model_ft.to(device)\r\n",
        "model.load_state_dict(torch.load(\"model_0.pth\"))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqeuozIpbLqS"
      },
      "source": [
        "class_names =  ['G1', 'S', 'G2']\r\n",
        "confusion_matrix = torch.zeros(len(class_names), len(class_names))\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    for i, data in enumerate(train_dl_sub, 0):\r\n",
        "        images, labels = data['x'], data['y']\r\n",
        "        images = images.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "        outputs = model(images)\r\n",
        "        _, preds = torch.max(outputs, 1)\r\n",
        "        for t, p in zip(labels.view(-1), preds.view(-1)):\r\n",
        "                confusion_matrix[t.long(), p.long()] += 1\r\n",
        "\r\n",
        "cm = confusion_matrix.numpy()\r\n",
        "fig = plt.figure(figsize=(6.5,6),  dpi = 80)\r\n",
        "ax = sns.heatmap(cm,\r\n",
        "                 annot=True, \r\n",
        "                 cmap='Blues', \r\n",
        "                 xticklabels = class_names, \r\n",
        "                 yticklabels = class_names, \r\n",
        "                 fmt='g')\r\n",
        "plt.ylabel('True label')\r\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMF9M-nJT0W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373423d8-6af9-479a-d317-0fc876e09059"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\r\n",
        "input = torch.randn(3, 5, requires_grad=True)\r\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\r\n",
        "loss = loss(input, target)\r\n",
        "loss"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.9511, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y_han0WahXW",
        "outputId": "5cb84cc9-1360-4d66-f3bd-6bc67c87951e"
      },
      "source": [
        "input"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.3267e-01, -2.1798e-01,  3.4201e-01,  4.9026e-04, -1.3770e+00],\n",
              "        [-5.9818e-01,  3.2150e-01,  4.0551e-01,  1.6947e-01,  1.4110e+00],\n",
              "        [-4.0916e-01, -1.9820e-01,  6.8735e-02,  3.3822e-01, -1.5905e-01]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WudCnBlfajRu",
        "outputId": "34e516d0-ab80-4963-dc80-4f28d89fac7e"
      },
      "source": [
        "target"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgsLhWv8uAZA",
        "outputId": "35c15d57-108f-4ff8-f66c-801839a1365f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#test_loss_fn\r\n",
        "def loss_fn(targets, outputs):\r\n",
        "        return nn.CrossEntropyLoss() (outputs, targets)\r\n",
        "loss_fn(target, input)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.9511, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AamOMQwKuExJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}